import cv2
import numpy as np
import mediapipe as mp
import time
import random
import string
from pynput import keyboard, mouse

# --- CONFIGURATION ---
# Gaze detection sensitivity. Lower numbers mean you have to look further away to trigger the effect.
# A good range is 0.1 to 0.3.
GAZE_THRESHOLD_X = 0.2
GAZE_THRESHOLD_Y = 0.2

# --- GLOBAL STATE VARIABLES ---
# These variables will be updated by the computer vision thread and read by the input listeners.
keyboard_should_scramble = False
mouse_should_invert = False
last_mouse_pos = (0, 0)
is_inverting_flag = False # Prevents recursive mouse events

# --- INITIALIZE MEDIAPIPE ---
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(
    max_num_faces=1,
    refine_landmarks=True,  # This is crucial for iris tracking
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5)

# --- KEYBOARD CONTROL ---
keyboard_controller = keyboard.Controller()

def get_random_char():
    """Returns a random lowercase letter."""
    return random.choice(string.ascii_lowercase)

def on_press(key):
    """Callback function for when a key is pressed."""
    global keyboard_should_scramble
    if keyboard_should_scramble:
        try:
            # Check if the key is an alphanumeric character
            if hasattr(key, 'char') and key.char and key.char.isalnum():
                random_char = get_random_char()
                # Use the controller to type the new character
                keyboard_controller.type(random_char)
                # Suppress the original key press by returning False
                return False
        except AttributeError:
            pass # Special keys (like Shift, Ctrl) will pass through

# Start the keyboard listener in a non-blocking way
keyboard_listener = keyboard.Listener(on_press=on_press)
keyboard_listener.start()


# --- MOUSE CONTROL ---
mouse_controller = mouse.Controller()

def on_move(x, y):
    """Callback function for when the mouse moves."""
    global mouse_should_invert, last_mouse_pos, is_inverting_flag

    if is_inverting_flag:
        return # This move event was generated by our own code, so ignore it

    # If mouse should be inverted
    if mouse_should_invert:
        # Calculate the delta from the last known position
        dx = x - last_mouse_pos[0]
        dy = y - last_mouse_pos[1]

        # Calculate the new inverted position
        inverted_x = last_mouse_pos[0] - dx
        inverted_y = last_mouse_pos[1] - dy
        
        # Set the flag to prevent recursion
        is_inverting_flag = True
        # Move the mouse to the inverted position
        mouse_controller.position = (inverted_x, inverted_y)
        is_inverting_flag = False
        
        # Update the last position to the new inverted position
        last_mouse_pos = (inverted_x, inverted_y)
    else:
        # If not inverting, just update the last known position
        last_mouse_pos = (x, y)

# Start the mouse listener
mouse_listener = mouse.Listener(on_move=on_move)
mouse_listener.start()


# --- MAIN COMPUTER VISION LOOP ---
def main():
    global keyboard_should_scramble, mouse_should_invert
    
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("Error: Cannot open webcam.")
        return

    print("Starting Gaze-Controlled Chaos...")
    print("Look away from the camera to scramble your keyboard.")
    print("Look at the camera to invert your mouse.")
    print("Press 'q' in the OpenCV window to quit.")

    while cap.isOpened():
        success, image = cap.read()
        if not success:
            continue

        # Flip the image horizontally for a later selfie-view display
        image = cv2.flip(image, 1)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = face_mesh.process(image_rgb)
        
        img_h, img_w, _ = image.shape

        if results.multi_face_landmarks:
            # Get landmarks for the first face
            face_landmarks = results.multi_face_landmarks[0].landmark
            
            # --- Gaze Detection Logic ---
            # Using left eye for gaze detection (landmarks 468-472)
            # and right eye (landmarks 473-477)
            
            # Get pixel coordinates for eye corners and iris centers
            left_eye_inner_corner = (face_landmarks[133].x * img_w, face_landmarks[133].y * img_h)
            left_eye_outer_corner = (face_landmarks[33].x * img_w, face_landmarks[33].y * img_h)
            left_iris_center = (face_landmarks[468].x * img_w, face_landmarks[468].y * img_h)

            right_eye_inner_corner = (face_landmarks[362].x * img_w, face_landmarks[362].y * img_h)
            right_eye_outer_corner = (face_landmarks[263].x * img_w, face_landmarks[263].y * img_h)
            right_iris_center = (face_landmarks[473].x * img_w, face_landmarks[473].y * img_h)

            # Calculate horizontal gaze ratio
            left_eye_width = left_eye_outer_corner[0] - left_eye_inner_corner[0]
            left_gaze_ratio = (left_iris_center[0] - left_eye_inner_corner[0]) / (left_eye_width + 1e-6)
            
            right_eye_width = right_eye_outer_corner[0] - right_eye_inner_corner[0]
            right_gaze_ratio = (right_iris_center[0] - right_eye_inner_corner[0]) / (right_eye_width + 1e-6)
            
            avg_gaze_ratio_x = (left_gaze_ratio + right_gaze_ratio) / 2

            # Basic vertical gaze (less reliable, but good enough for this)
            eye_top = (face_landmarks[159].y * img_h)
            eye_bottom = (face_landmarks[145].y * img_h)
            eye_height = eye_bottom - eye_top
            vertical_gaze_ratio = (left_iris_center[1] - eye_top) / (eye_height + 1e-6)

            # --- Update State ---
            # Check if gaze is outside the center "safe zone"
            if (avg_gaze_ratio_x < 0.5 - GAZE_THRESHOLD_X or 
                avg_gaze_ratio_x > 0.5 + GAZE_THRESHOLD_X or
                vertical_gaze_ratio < 0.5 - GAZE_THRESHOLD_Y or
                vertical_gaze_ratio > 0.5 + GAZE_THRESHOLD_Y):
                # LOOKING AWAY: Scramble keyboard, normal mouse
                keyboard_should_scramble = True
                mouse_should_invert = False
                status_text = "MODE: KEYBOARD CHAOS"
                status_color = (0, 0, 255) # Red
            else:
                # LOOKING AT SCREEN: Normal keyboard, invert mouse
                keyboard_should_scramble = False
                mouse_should_invert = True
                status_text = "MODE: MOUSE INVERSION"
                status_color = (0, 255, 0) # Green
        else:
            # NO FACE DETECTED: Everything is normal
            keyboard_should_scramble = False
            mouse_should_invert = False
            status_text = "MODE: NORMAL (No face detected)"
            status_color = (255, 255, 255) # White

        # --- Display Visual Feedback ---
        cv2.putText(image, status_text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, status_color, 2)
        cv2.imshow('Gaze-Controlled Chaos', image)

        if cv2.waitKey(5) & 0xFF == ord('q'):
            break

    # --- Cleanup ---
    print("Stopping listeners and cleaning up...")
    cap.release()
    cv2.destroyAllWindows()
    keyboard_listener.stop()
    mouse_listener.stop()
    face_mesh.close()

if __name__ == '__main__':
    main()
